{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n",
      "1903\n",
      "Word2Vec(vocab=27, size=1903, alpha=0.025)\n",
      "[' ', \"'\", ',', '.', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'm', 'l', 'o', 'n', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'how' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-324621fd676d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'how'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gensim/models/keyedvectors.pyc\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'how' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "text = open(\"text.txt\").read()\n",
    "text = text.lower()\n",
    "text = text.split()\n",
    "text = str(text)\n",
    "print type(text)\n",
    "print len(text)\n",
    "model = Word2Vec(text ,size=1903)\n",
    "print model\n",
    "sample = list(model.wv.vocab)\n",
    "print sample\n",
    "print(model.wv['how'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "t\n",
      "is\n",
      "defining\n",
      "[['t', 'is', 'defining', 'a', 'word', 'by', 'the', 'company', 'that', 'it', 'keeps', 'that', 'allows', 'the', 'word', 'embedding', 'to', 'learn', 'something', 'about', 'the', 'meaning', 'of', 'words'], ['the', 'vector', 'space', 'representation', 'of', 'the', 'words', 'provides', 'a', 'projection', 'where', 'words', 'with', 'similar', 'meanings', 'are', 'locally', 'clustered', 'within', 'the', 'space'], ['the', 'use', 'of', 'word', 'embeddings', 'over', 'other', 'text', 'representations', 'is', 'one', 'of', 'the', 'key', 'methods', 'that', 'has', 'led', 'to', 'breakthrough', 'performance', 'with', 'deep', 'neural', 'networks', 'on', 'problems', 'like', 'machine', 'translation'], ['in', 'this', 'tutorial,', 'we', 'are', 'going', 'to', 'look', 'at', 'how', 'to', 'use', 'two', 'different', 'word', 'embedding', 'methods', 'called', 'word2vec', 'by', 'researchers', 'at', 'google', 'and', 'glove', 'by', 'researchers', 'at', 'stanford'], ['here', 'are', 'two', 'main', 'training', 'algorithms', 'that', 'can', 'be', 'used', 'to', 'learn', 'the', 'embedding', 'from', 'text;', 'they', 'are', 'continuous', 'bag', 'of', 'words', '(cbow)', 'and', 'skip', 'grams'], ['we', 'will', 'not', 'get', 'into', 'the', 'algorithms', 'other', 'than', 'to', 'say', 'that', 'they', 'generally', 'look', 'at', 'a', 'window', 'of', 'words', 'for', 'each', 'target', 'word', 'to', 'provide', 'context', 'and', 'in', 'turn', 'meaning', 'for', 'words'], ['the', 'approach', 'was', 'developed', 'by', 'tomas', 'mikolov,', 'formerly', 'at', 'google', 'and', 'currently', 'at', 'facebook'], ['word2vec', 'models', 'require', 'a', 'lot', 'of', 'text,', 'e'], ['g'], ['the', 'entire', 'wikipedia', 'corpus'], ['nevertheless,', 'we', 'will', 'demonstrate', 'the', 'principles', 'using', 'a', 'small', 'in-memory', 'example', 'of', 'text'], ['gensim', 'provides', 'the', 'word2vec', 'class', 'for', 'working', 'with', 'a', 'word2vec', 'model'], []]\n"
     ]
    }
   ],
   "source": [
    "text = open(\"text.txt\").read()\n",
    "text = text.lower()\n",
    "words = []\n",
    "for word in text.split():\n",
    "    if word != \".\":\n",
    "        words.append(word)\n",
    "        \n",
    "#print words\n",
    "\n",
    "newwords = set(words)\n",
    "\n",
    "#print newwords\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "for i,word in enumerate(words):\n",
    "        word2int[word] = i\n",
    "        int2word[i] = word\n",
    "        \n",
    "print(word2int['how'])\n",
    "print(int2word[0])\n",
    "print(int2word[1])\n",
    "print(int2word[2])\n",
    "\n",
    "sentencelist = []\n",
    "text = text.split('.')\n",
    "for sentence in text:\n",
    "    sentencelist.append(sentence.split())\n",
    "    \n",
    "\n",
    "print sentencelist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
