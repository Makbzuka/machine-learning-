{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re\n",
    "import nltk\n",
    "import gensim.models.word2vec as w2v\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) #lets log everything "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/codejunky237/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codejunky237/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\") #splitting text in to sentences\n",
    "nltk.download(\"stopwords\") # getting all un neccessary words link ,'and' 'or' out of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "book_filenames = sorted(glob.glob(\"/home/codejunky237/ml/word2vec/word_vectors_game_of_thrones-LIVE/data/*.txt\"))\n",
    "print(type(book_filenames))\n",
    "print(len(book_filenames))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is this format '/home/codejunky237/ml/word2vec/word_vectors_game_of_thrones-LIVE/data/got1.txt'\n",
      "Corpus is now 1770659 characters long\n",
      "<type 'unicode'>\n",
      "what is this format '/home/codejunky237/ml/word2vec/word_vectors_game_of_thrones-LIVE/data/got2.txt'\n",
      "Corpus is now 4071041 characters long\n",
      "<type 'unicode'>\n",
      "what is this format '/home/codejunky237/ml/word2vec/word_vectors_game_of_thrones-LIVE/data/got3.txt'\n",
      "Corpus is now 6391405 characters long\n",
      "<type 'unicode'>\n",
      "what is this format '/home/codejunky237/ml/word2vec/word_vectors_game_of_thrones-LIVE/data/got4.txt'\n",
      "Corpus is now 8107945 characters long\n",
      "<type 'unicode'>\n",
      "what is this format '/home/codejunky237/ml/word2vec/word_vectors_game_of_thrones-LIVE/data/got5.txt'\n",
      "Corpus is now 9719485 characters long\n",
      "<type 'unicode'>\n"
     ]
    }
   ],
   "source": [
    "# create a corpus of the books\n",
    "word_corpus = u\"\"\n",
    "for book_filename in book_filenames:\n",
    "    print(\"what is this format '{0}'\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\",\"utf-8\") as bk: # open books with utf-8 format\n",
    "        word_corpus += bk.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(word_corpus)))\n",
    "    print(type(word_corpus))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle') #get sentences from text in unicode format\n",
    "raw_words = tokenizer.tokenize(word_corpus)\n",
    "print(raw_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128868\n",
      "This edition contains the complete text of the original hardcover edition.\n",
      "[u'This', u'edition', u'contains', u'the', u'complete', u'text', u'of', u'the', u'original', u'hardcover', u'edition']\n"
     ]
    }
   ],
   "source": [
    "#clean the data\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words\n",
    "\n",
    "sentence_list = []\n",
    "\n",
    "for sentence in raw_words:\n",
    "    if len(sentence) > 0 :\n",
    "        sentence_list.append(sentence_to_wordlist(sentence))\n",
    "print(len(sentence_list))\n",
    "print(raw_words[0])\n",
    "print(sentence_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the token coun '1818103'\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentence_list])\n",
    "print(\"the token coun '{0}'\".format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step we build the model\n",
    "# dimensionality of the resulting vector \n",
    "num_features = 300 # less dimensionality easy to train \n",
    "min_word_count = 3\n",
    "num_workers = multiprocessing.cpu_count() #number of workers \n",
    "\n",
    "context_window = 7 # number of surrounding names for each selected word\n",
    "down_sampling = 1e-3 #reducing sample size\n",
    "seed = 1\n",
    "thrones2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_window,\n",
    "    sample=down_sampling\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-12 13:55:34,834 : INFO : collecting all words and their counts\n",
      "2018-06-12 13:55:34,837 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-06-12 13:55:34,908 : INFO : PROGRESS: at sentence #10000, processed 140984 words, keeping 10280 word types\n",
      "2018-06-12 13:55:34,976 : INFO : PROGRESS: at sentence #20000, processed 279730 words, keeping 13558 word types\n",
      "2018-06-12 13:55:35,049 : INFO : PROGRESS: at sentence #30000, processed 420336 words, keeping 16598 word types\n",
      "2018-06-12 13:55:35,113 : INFO : PROGRESS: at sentence #40000, processed 556581 words, keeping 18324 word types\n",
      "2018-06-12 13:55:35,175 : INFO : PROGRESS: at sentence #50000, processed 686247 words, keeping 19714 word types\n",
      "2018-06-12 13:55:35,237 : INFO : PROGRESS: at sentence #60000, processed 828497 words, keeping 21672 word types\n",
      "2018-06-12 13:55:35,299 : INFO : PROGRESS: at sentence #70000, processed 973830 words, keeping 23093 word types\n",
      "2018-06-12 13:55:35,361 : INFO : PROGRESS: at sentence #80000, processed 1114967 words, keeping 24252 word types\n",
      "2018-06-12 13:55:35,434 : INFO : PROGRESS: at sentence #90000, processed 1260481 words, keeping 26007 word types\n",
      "2018-06-12 13:55:35,490 : INFO : PROGRESS: at sentence #100000, processed 1393203 words, keeping 26884 word types\n",
      "2018-06-12 13:55:35,552 : INFO : PROGRESS: at sentence #110000, processed 1532150 words, keeping 27809 word types\n",
      "2018-06-12 13:55:35,614 : INFO : PROGRESS: at sentence #120000, processed 1680961 words, keeping 28486 word types\n",
      "2018-06-12 13:55:35,678 : INFO : collected 29026 word types from a corpus of 1818103 raw words and 128868 sentences\n",
      "2018-06-12 13:55:35,680 : INFO : Loading a fresh vocabulary\n",
      "2018-06-12 13:55:35,757 : INFO : min_count=3 retains 17277 unique words (59% of original 29026, drops 11749)\n",
      "2018-06-12 13:55:35,759 : INFO : min_count=3 leaves 1802699 word corpus (99% of original 1818103, drops 15404)\n",
      "2018-06-12 13:55:35,847 : INFO : deleting the raw counts dictionary of 29026 items\n",
      "2018-06-12 13:55:35,852 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2018-06-12 13:55:35,854 : INFO : downsampling leaves estimated 1404424 word corpus (77.9% of prior 1802699)\n",
      "2018-06-12 13:55:35,935 : INFO : estimated required memory for 17277 words and 300 dimensions: 50103300 bytes\n",
      "2018-06-12 13:55:35,936 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.build_vocab(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 17277\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Word2Vec vocabulary length:\", len(thrones2vec.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-12 14:32:42,982 : INFO : training model with 4 workers on 17277 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=7\n",
      "2018-06-12 14:32:44,234 : INFO : EPOCH 1 - PROGRESS: at 5.41% examples, 76456 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:45,273 : INFO : EPOCH 1 - PROGRESS: at 13.30% examples, 90599 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:46,326 : INFO : EPOCH 1 - PROGRESS: at 21.50% examples, 96955 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:47,335 : INFO : EPOCH 1 - PROGRESS: at 30.03% examples, 101422 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:48,344 : INFO : EPOCH 1 - PROGRESS: at 39.54% examples, 105607 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:49,350 : INFO : EPOCH 1 - PROGRESS: at 46.57% examples, 104612 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:50,403 : INFO : EPOCH 1 - PROGRESS: at 55.13% examples, 106510 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:51,435 : INFO : EPOCH 1 - PROGRESS: at 63.32% examples, 107311 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:52,445 : INFO : EPOCH 1 - PROGRESS: at 71.52% examples, 108015 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:53,468 : INFO : EPOCH 1 - PROGRESS: at 79.12% examples, 107032 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:54,470 : INFO : EPOCH 1 - PROGRESS: at 86.30% examples, 106376 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:55,559 : INFO : EPOCH 1 - PROGRESS: at 94.47% examples, 106933 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:56,156 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:32:56,175 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:32:56,195 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:32:56,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-12 14:32:56,227 : INFO : EPOCH - 1 : training on 1818103 raw words (1404254 effective words) took 13.0s, 107998 effective words/s\n",
      "2018-06-12 14:32:57,399 : INFO : EPOCH 2 - PROGRESS: at 7.09% examples, 89233 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:58,432 : INFO : EPOCH 2 - PROGRESS: at 14.42% examples, 92387 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:32:59,559 : INFO : EPOCH 2 - PROGRESS: at 23.22% examples, 97823 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:00,640 : INFO : EPOCH 2 - PROGRESS: at 32.42% examples, 101929 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:01,673 : INFO : EPOCH 2 - PROGRESS: at 42.08% examples, 105309 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:02,730 : INFO : EPOCH 2 - PROGRESS: at 49.84% examples, 106119 words/s, in_qsize 7, out_qsize 1\n",
      "2018-06-12 14:33:03,778 : INFO : EPOCH 2 - PROGRESS: at 57.82% examples, 106628 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:33:04,834 : INFO : EPOCH 2 - PROGRESS: at 66.18% examples, 107943 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:05,900 : INFO : EPOCH 2 - PROGRESS: at 75.70% examples, 108824 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:06,969 : INFO : EPOCH 2 - PROGRESS: at 84.10% examples, 108736 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:08,035 : INFO : EPOCH 2 - PROGRESS: at 92.42% examples, 109320 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:33:08,881 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:33:08,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:33:08,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:33:08,976 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-12 14:33:08,978 : INFO : EPOCH - 2 : training on 1818103 raw words (1404997 effective words) took 12.7s, 110357 effective words/s\n",
      "2018-06-12 14:33:10,040 : INFO : EPOCH 3 - PROGRESS: at 7.09% examples, 95120 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:11,096 : INFO : EPOCH 3 - PROGRESS: at 16.05% examples, 106664 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:33:12,137 : INFO : EPOCH 3 - PROGRESS: at 24.34% examples, 107807 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:33:13,183 : INFO : EPOCH 3 - PROGRESS: at 33.56% examples, 110427 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:14,250 : INFO : EPOCH 3 - PROGRESS: at 43.14% examples, 111475 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:15,357 : INFO : EPOCH 3 - PROGRESS: at 51.41% examples, 111540 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:16,416 : INFO : EPOCH 3 - PROGRESS: at 60.04% examples, 112321 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:17,439 : INFO : EPOCH 3 - PROGRESS: at 67.86% examples, 112394 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:18,542 : INFO : EPOCH 3 - PROGRESS: at 77.28% examples, 112329 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:19,642 : INFO : EPOCH 3 - PROGRESS: at 86.30% examples, 112292 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:20,768 : INFO : EPOCH 3 - PROGRESS: at 94.47% examples, 111982 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:21,323 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:33:21,328 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:33:21,349 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:33:21,384 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-12 14:33:21,386 : INFO : EPOCH - 3 : training on 1818103 raw words (1404608 effective words) took 12.4s, 113275 effective words/s\n",
      "2018-06-12 14:33:22,456 : INFO : EPOCH 4 - PROGRESS: at 7.09% examples, 96903 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:33:23,485 : INFO : EPOCH 4 - PROGRESS: at 15.52% examples, 104055 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:24,569 : INFO : EPOCH 4 - PROGRESS: at 24.34% examples, 107383 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:25,664 : INFO : EPOCH 4 - PROGRESS: at 33.56% examples, 108860 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:26,729 : INFO : EPOCH 4 - PROGRESS: at 43.14% examples, 110274 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:27,749 : INFO : EPOCH 4 - PROGRESS: at 50.87% examples, 110833 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:28,774 : INFO : EPOCH 4 - PROGRESS: at 58.34% examples, 110283 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:33:29,850 : INFO : EPOCH 4 - PROGRESS: at 66.71% examples, 110683 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:30,978 : INFO : EPOCH 4 - PROGRESS: at 76.24% examples, 110535 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:32,012 : INFO : EPOCH 4 - PROGRESS: at 85.13% examples, 111363 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:33,026 : INFO : EPOCH 4 - PROGRESS: at 92.42% examples, 110903 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:33,880 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:33:33,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:33:33,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:33:34,069 : INFO : EPOCH 4 - PROGRESS: at 100.00% examples, 110907 words/s, in_qsize 0, out_qsize 1\n",
      "2018-06-12 14:33:34,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-12 14:33:34,072 : INFO : EPOCH - 4 : training on 1818103 raw words (1404588 effective words) took 12.7s, 110880 effective words/s\n",
      "2018-06-12 14:33:35,132 : INFO : EPOCH 5 - PROGRESS: at 7.09% examples, 96631 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:36,140 : INFO : EPOCH 5 - PROGRESS: at 15.52% examples, 105703 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:37,246 : INFO : EPOCH 5 - PROGRESS: at 22.68% examples, 100375 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:38,288 : INFO : EPOCH 5 - PROGRESS: at 30.03% examples, 99796 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:33:39,325 : INFO : EPOCH 5 - PROGRESS: at 39.54% examples, 103420 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:40,417 : INFO : EPOCH 5 - PROGRESS: at 47.71% examples, 103869 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:41,541 : INFO : EPOCH 5 - PROGRESS: at 55.13% examples, 102728 words/s, in_qsize 7, out_qsize 1\n",
      "2018-06-12 14:33:42,596 : INFO : EPOCH 5 - PROGRESS: at 63.26% examples, 103680 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-12 14:33:43,663 : INFO : EPOCH 5 - PROGRESS: at 70.29% examples, 102581 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:44,712 : INFO : EPOCH 5 - PROGRESS: at 77.37% examples, 101159 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:45,712 : INFO : EPOCH 5 - PROGRESS: at 84.49% examples, 100409 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:46,754 : INFO : EPOCH 5 - PROGRESS: at 89.98% examples, 98918 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:47,765 : INFO : EPOCH 5 - PROGRESS: at 96.47% examples, 98801 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:48,078 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:33:48,140 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:33:48,165 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:33:48,239 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-12 14:33:48,240 : INFO : EPOCH - 5 : training on 1818103 raw words (1405104 effective words) took 14.1s, 99331 effective words/s\n",
      "2018-06-12 14:33:49,247 : INFO : EPOCH 6 - PROGRESS: at 4.84% examples, 69418 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:50,280 : INFO : EPOCH 6 - PROGRESS: at 13.83% examples, 95612 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:33:51,475 : INFO : EPOCH 6 - PROGRESS: at 20.92% examples, 90735 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:52,637 : INFO : EPOCH 6 - PROGRESS: at 30.03% examples, 94938 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:53,640 : INFO : EPOCH 6 - PROGRESS: at 39.54% examples, 100196 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:54,648 : INFO : EPOCH 6 - PROGRESS: at 48.23% examples, 103683 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:55,650 : INFO : EPOCH 6 - PROGRESS: at 55.67% examples, 104302 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:56,663 : INFO : EPOCH 6 - PROGRESS: at 63.84% examples, 105578 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:57,793 : INFO : EPOCH 6 - PROGRESS: at 72.76% examples, 105965 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:33:58,844 : INFO : EPOCH 6 - PROGRESS: at 81.54% examples, 106386 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:33:59,906 : INFO : EPOCH 6 - PROGRESS: at 88.47% examples, 105288 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:00,964 : INFO : EPOCH 6 - PROGRESS: at 95.99% examples, 105577 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:01,293 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:34:01,392 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:34:01,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:34:01,430 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-12 14:34:01,432 : INFO : EPOCH - 6 : training on 1818103 raw words (1404918 effective words) took 13.2s, 106552 effective words/s\n",
      "2018-06-12 14:34:02,445 : INFO : EPOCH 7 - PROGRESS: at 6.51% examples, 92194 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:34:03,532 : INFO : EPOCH 7 - PROGRESS: at 13.30% examples, 88589 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:04,613 : INFO : EPOCH 7 - PROGRESS: at 20.37% examples, 90229 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:05,629 : INFO : EPOCH 7 - PROGRESS: at 27.71% examples, 92169 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:06,670 : INFO : EPOCH 7 - PROGRESS: at 36.61% examples, 96002 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:07,700 : INFO : EPOCH 7 - PROGRESS: at 45.49% examples, 99884 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:08,750 : INFO : EPOCH 7 - PROGRESS: at 54.05% examples, 102447 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:09,789 : INFO : EPOCH 7 - PROGRESS: at 62.25% examples, 103631 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:10,964 : INFO : EPOCH 7 - PROGRESS: at 70.93% examples, 103775 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:12,029 : INFO : EPOCH 7 - PROGRESS: at 78.48% examples, 102824 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:13,236 : INFO : EPOCH 7 - PROGRESS: at 86.85% examples, 102093 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:34:14,295 : INFO : EPOCH 7 - PROGRESS: at 92.94% examples, 100846 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:14,970 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:34:15,044 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:34:15,110 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:34:15,116 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-12 14:34:15,118 : INFO : EPOCH - 7 : training on 1818103 raw words (1404508 effective words) took 13.7s, 102691 effective words/s\n",
      "2018-06-12 14:34:16,138 : INFO : EPOCH 8 - PROGRESS: at 6.51% examples, 90907 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:17,149 : INFO : EPOCH 8 - PROGRESS: at 14.42% examples, 98929 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:34:18,155 : INFO : EPOCH 8 - PROGRESS: at 22.68% examples, 104145 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:19,213 : INFO : EPOCH 8 - PROGRESS: at 31.78% examples, 107518 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:20,227 : INFO : EPOCH 8 - PROGRESS: at 40.81% examples, 108852 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:21,325 : INFO : EPOCH 8 - PROGRESS: at 49.29% examples, 109545 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:22,375 : INFO : EPOCH 8 - PROGRESS: at 57.82% examples, 110705 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:23,393 : INFO : EPOCH 8 - PROGRESS: at 66.04% examples, 111130 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:24,477 : INFO : EPOCH 8 - PROGRESS: at 75.10% examples, 111396 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:25,561 : INFO : EPOCH 8 - PROGRESS: at 84.49% examples, 111638 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:26,592 : INFO : EPOCH 8 - PROGRESS: at 92.42% examples, 112293 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:27,395 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:34:27,402 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:34:27,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:34:27,548 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-12 14:34:27,551 : INFO : EPOCH - 8 : training on 1818103 raw words (1403878 effective words) took 12.4s, 112954 effective words/s\n",
      "2018-06-12 14:34:28,592 : INFO : EPOCH 9 - PROGRESS: at 7.09% examples, 98184 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:29,602 : INFO : EPOCH 9 - PROGRESS: at 16.05% examples, 109540 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:30,655 : INFO : EPOCH 9 - PROGRESS: at 24.89% examples, 112060 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:31,718 : INFO : EPOCH 9 - PROGRESS: at 33.56% examples, 111380 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:32,756 : INFO : EPOCH 9 - PROGRESS: at 42.68% examples, 111400 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:33,775 : INFO : EPOCH 9 - PROGRESS: at 50.38% examples, 111754 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:34,800 : INFO : EPOCH 9 - PROGRESS: at 57.82% examples, 110895 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:35,826 : INFO : EPOCH 9 - PROGRESS: at 65.57% examples, 110270 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:36,846 : INFO : EPOCH 9 - PROGRESS: at 71.52% examples, 107238 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:37,989 : INFO : EPOCH 9 - PROGRESS: at 78.99% examples, 105100 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:39,072 : INFO : EPOCH 9 - PROGRESS: at 87.94% examples, 105910 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:40,088 : INFO : EPOCH 9 - PROGRESS: at 95.53% examples, 106524 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:40,498 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:34:40,564 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:34:40,657 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:34:40,697 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-12 14:34:40,698 : INFO : EPOCH - 9 : training on 1818103 raw words (1404765 effective words) took 13.1s, 106899 effective words/s\n",
      "2018-06-12 14:34:41,727 : INFO : EPOCH 10 - PROGRESS: at 5.45% examples, 75621 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:42,763 : INFO : EPOCH 10 - PROGRESS: at 12.64% examples, 86288 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:43,808 : INFO : EPOCH 10 - PROGRESS: at 20.92% examples, 94396 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:44,856 : INFO : EPOCH 10 - PROGRESS: at 28.24% examples, 94836 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:45,949 : INFO : EPOCH 10 - PROGRESS: at 35.36% examples, 92803 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:46,978 : INFO : EPOCH 10 - PROGRESS: at 43.14% examples, 93565 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:48,000 : INFO : EPOCH 10 - PROGRESS: at 50.87% examples, 96367 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:49,033 : INFO : EPOCH 10 - PROGRESS: at 58.34% examples, 97407 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:50,208 : INFO : EPOCH 10 - PROGRESS: at 66.18% examples, 97573 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:51,258 : INFO : EPOCH 10 - PROGRESS: at 74.55% examples, 98080 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:52,292 : INFO : EPOCH 10 - PROGRESS: at 83.49% examples, 99311 words/s, in_qsize 7, out_qsize 0\n",
      "2018-06-12 14:34:53,522 : INFO : EPOCH 10 - PROGRESS: at 90.46% examples, 98144 words/s, in_qsize 8, out_qsize 0\n",
      "2018-06-12 14:34:54,691 : INFO : EPOCH 10 - PROGRESS: at 97.98% examples, 98204 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-12 14:34:54,723 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-06-12 14:34:54,728 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-12 14:34:54,739 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-12 14:34:54,872 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-12 14:34:54,873 : INFO : EPOCH - 10 : training on 1818103 raw words (1404652 effective words) took 14.2s, 99151 effective words/s\n",
      "2018-06-12 14:34:54,875 : INFO : training on a 18181030 raw words (14046272 effective words) took 131.9s, 106503 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14046272, 18181030)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.train(sentence_list,total_examples = thrones2vec.corpus_count,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2018-06-12 14:36:37,800 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'Eddard', 0.6736850738525391),\n",
       " (u'executed', 0.5348050594329834),\n",
       " (u'divulge', 0.507888913154602),\n",
       " (u'ROSLIN', 0.4971054792404175),\n",
       " (u'Winterfell', 0.49284863471984863),\n",
       " (u'Knelt', 0.48720240592956543),\n",
       " (u'Edrick', 0.485209584236145),\n",
       " (u'Burner', 0.48321765661239624),\n",
       " (u'absently', 0.482699453830719),\n",
       " (u'Snowbeard', 0.48158159852027893)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.most_similar(\"Stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'Snow', 0.6602096557617188),\n",
       " (u'Ygritte', 0.5214747786521912),\n",
       " (u'Qhorin', 0.5154229402542114),\n",
       " (u'Stonesnake', 0.4834851026535034),\n",
       " (u'Orell', 0.46222802996635437),\n",
       " (u'Benjen', 0.4532366991043091),\n",
       " (u'Val', 0.4521523118019104),\n",
       " (u'Ghost', 0.45110154151916504),\n",
       " (u'cackling', 0.45073816180229187),\n",
       " (u'Coldhands', 0.45026370882987976)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.most_similar(\"Jon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
